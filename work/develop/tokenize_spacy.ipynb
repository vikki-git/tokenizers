{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_parser = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/initial.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Docker', 'is', 'used', 'to', 'run', 'software', 'packages', 'called', '\"', 'containers', '\"', '.', 'In', 'a', 'typical', 'example', 'use', 'case', ',', 'one', 'container', 'runs', 'a', 'web', 'server', 'and', 'web', 'application', ',', 'while', 'a', 'second', 'container', 'runs', 'a', 'database', 'server', 'that', 'is', 'used', 'by', 'the', 'web', 'application.[citation', 'needed', ']', 'Containers', 'are', 'isolated', 'from', 'each', 'other', 'and', 'bundle', 'their', 'own', 'tools', ',', 'libraries', 'and', 'configuration', 'files', ';', 'they', 'can', 'communicate', 'with', 'each', 'other', 'through', 'well', '-', 'defined', 'channels', '.', 'All', 'containers', 'are', 'run', 'by', 'a', 'single', 'operating', 'system', 'kernel', 'and', 'are', 'thus', 'more', 'lightweight', 'than', 'virtual', 'machines', '.', 'Containers', 'are', 'created', 'from', '\"', 'images', '\"', 'that', 'specify', 'their', 'precise', 'contents', '.', 'Images', 'are', 'often', 'created', 'by', 'combining', 'and', 'modifying', 'standard', 'images', 'downloaded', 'from', 'repositories', '.', 'Docker', 'is', 'used', 'to', 'run', 'software', 'packages', 'called', '\"', 'containers', '\"', '.', 'In', 'a', 'typical', 'example', 'use', 'case', ',', 'one', 'container', 'runs', 'a', 'web', 'server', 'and', 'web', 'application', ',', 'while', 'a', 'second', 'container', 'runs', 'a', 'database', 'server', 'that', 'is', 'used', 'by', 'the', 'web', 'application.[citation', 'needed', ']', 'Containers', 'are', 'isolated', 'from', 'each', 'other', 'and', 'bundle', 'their', 'own', 'tools', ',', 'libraries', 'and', 'configuration', 'files', ';', 'they', 'can', 'communicate', 'with', 'each', 'other', 'through', 'well', '-', 'defined', 'channels', '.', 'All', 'containers', 'are', 'run', 'by', 'a', 'single', 'operating', 'system', 'kernel', 'and', 'are', 'thus', 'more', 'lightweight', 'than', 'virtual', 'machines', '.', 'Containers', 'are', 'created', 'from', '\"', 'images', '\"', 'that', 'specify', 'their', 'precise', 'contents', '.', 'Images', 'are', 'often', 'created', 'by', 'combining', 'and', 'modifying', 'standard', 'images', 'downloaded', 'from', 'repositories', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp_parser(text)\n",
    "tokens = [token.orth_ for token in tokens if not token.orth_.isspace()]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_tokenized_spacy = '../data/tokenized_spacy.txt'\n",
    "file = open(filename_tokenized_spacy, 'w')\n",
    "file.write('\\n'.join(tokens))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
